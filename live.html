<!doctype html>
<html lang="de">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width,initial-scale=1"/>
  <title>Clarity Live Interview (Realtime + Recording → Mux)</title>
  <style>
    :root { --bg:#0b0d12; --fg:#e5e7eb; --muted:#9ca3af; --accent:#60a5fa; }
    body{margin:0;font-family:ui-sans-serif,system-ui,Segoe UI,Roboto,Arial;background:var(--bg);color:var(--fg)}
    .wrap{max-width:980px;margin:0 auto;padding:16px}
    .row{display:grid;grid-template-columns:1fr 1fr;gap:16px}
    .card{background:#0f1320;border:1px solid #1f2937;border-radius:14px;padding:16px;box-shadow:0 10px 30px rgba(0,0,0,.25)}
    h1{font-size:20px;margin:0 0 12px}
    label{display:block;margin:8px 0 6px;color:var(--muted)}
    input,button,textarea,select{width:100%;padding:10px 12px;border-radius:10px;border:1px solid #303b4a;background:#0b1220;color:var(--fg)}
    button{background:#10182b;cursor:pointer}
    button.primary{background:linear-gradient(135deg,#2563eb,#0ea5e9);border:none}
    button:disabled{opacity:.5;cursor:not-allowed}
    .status{font-family:ui-monospace,Consolas,monospace;font-size:12px;background:#0b1220;border:1px dashed #293243;border-radius:10px;padding:10px;height:170px;overflow:auto;white-space:pre-wrap}
    audio,video{width:100%}
    .pill{display:inline-block;background:#111827;border:1px solid #374151;border-radius:999px;padding:4px 10px;font-size:12px;margin-right:6px}
    .row2{display:grid;grid-template-columns:1fr 1fr;gap:12px;margin-top:12px}
  </style>
</head>
<body>
<div class="wrap">
  <h1>Clarity Live Interview (Realtime + Recording → Mux)</h1>

  <div class="row">
    <div class="card">
      <label>Session</label>
      <div id="pills">
        <span class="pill" id="pillState">state: idle</span>
        <span class="pill" id="pillModel">model: —</span>
        <span class="pill" id="pillRec">record: off</span>
      </div>

      <label>UID</label><input id="inUid" placeholder="UID (linkId)"/>
      <label>Company ID</label><input id="inCompany" placeholder="companyId"/>
      <label>Language</label>
      <select id="inLang"><option value="de">de</option><option value="en">en</option></select>
      <label>Voice</label>
      <select id="inVoice">
        <option value="verse">verse</option><option value="alloy">alloy</option><option value="ash">ash</option>
      </select>

      <div class="row2">
        <div>
          <label>Token Endpoint</label>
          <input id="inTokenUrl" value="" placeholder="/api/wix-token-proxy (fallback: /_functions/realtimeToken)"/>
        </div>
        <div>
          <label>Mux Upload API</label>
          <input id="inMuxUpload" value="" placeholder="/api/mux-upload (fallback: /_functions/muxUpload)"/>
        </div>
      </div>

      <div style="display:flex;gap:8px;margin-top:12px">
        <button id="btnStart" class="primary">Start Live</button>
        <button id="btnStop">Stop</button>
        <button id="btnToggleRec">Record to Mux: On</button>
      </div>

      <label style="margin-top:14px">Status</label>
      <div id="log" class="status"></div>
    </div>

    <div class="card">
      <label>Agent Audio</label>
      <audio id="agentAudio" autoplay playsinline></audio>

      <label>Preview (Your Camera)</label>
      <video id="preview" autoplay playsinline muted></video>

      <label>Agent Text</label>
      <textarea id="agentText" rows="6" placeholder="Agent messages…"></textarea>
    </div>
  </div>
</div>

<script>
const els = {
  uid: q('#inUid'), company: q('#inCompany'), lang: q('#inLang'), voice: q('#inVoice'),
  tokenUrl: q('#inTokenUrl'), muxUpload: q('#inMuxUpload'),
  start: q('#btnStart'), stop: q('#btnStop'), toggleRec: q('#btnToggleRec'),
  audio: q('#agentAudio'), text: q('#agentText'), log: q('#log'),
  pillState: q('#pillState'), pillModel: q('#pillModel'), pillRec: q('#pillRec'),
  preview: q('#preview')
};
function q(s){ return document.querySelector(s); }
function log(...a){ const t=a.map(x=>typeof x==='object'?JSON.stringify(x):String(x)).join(' '); els.log.textContent+=`[${new Date().toLocaleTimeString()}] ${t}\n`; els.log.scrollTop=els.log.scrollHeight; console.log(...a); }
function setState(s){ els.pillState.textContent=`state: ${s}` }

let pc=null, dc=null, stream=null, modelInUse=null;
let mediaRecorder=null, chunks=[], doRecording=true;
let muxUploadUrl=null, muxUploadId=null;
let audioCtx = null;

// response.create Serialisierung (verhindert "active response in progress")
let activeResponseId = null;
let queuedResponsePayload = null;

// Prefill & Defaults + Fallback-Routen
(()=> {
  const p = new URLSearchParams(location.search);
  if(p.get('uid')) els.uid.value=p.get('uid');
  if(p.get('companyId')) els.company.value=p.get('companyId');
  if(p.get('lang')) els.lang.value=p.get('lang');
  if(p.get('voice')) els.voice.value=p.get('voice');

  const defaultToken = '/api/wix-token-proxy';
  const defaultMux   = '/api/mux-upload';
  els.tokenUrl.value = p.get('tokenUrl') || defaultToken;
  els.muxUpload.value= p.get('muxUrl')  || defaultMux;
  log('Token endpoint:', els.tokenUrl.value, 'Mux endpoint:', els.muxUpload.value);
})();

// UI
els.start.addEventListener('click', startLive);
els.stop.addEventListener('click', stopLive);
els.toggleRec.addEventListener('click', ()=> setRecording(!doRecording));

function setRecording(v){
  doRecording=!!v;
  els.pillRec.textContent=`record: ${doRecording?'on':'off'}`;
  els.toggleRec.textContent=`Record to Mux: ${doRecording?'On':'Off'}`;
}

// postMessage hooks (kannst du später fürs Iframe nutzen)
window.addEventListener('message', async (ev)=>{
  const {type,data}=ev.data||{};
  if(type==='clarity.live.start'){
    if(data?.uid) els.uid.value=data.uid;
    if(data?.companyId) els.company.value=data.companyId;
    if(data?.lang) els.lang.value=data.lang;
    await startLive();
  }
  if(type==='clarity.live.stop'){ await stopLive(); }
  if(type==='clarity.live.record'){ setRecording(!!data?.enabled); }
  if(type==='clarity.live.context'){
    if(dc && dc.readyState==='open'){
      dc.send(JSON.stringify({ type:'session.update', session:{ instructions: buildSystemInstructions(data) }}));
    }
  }
});

function buildSystemInstructions(ctx){
  const companyName = ctx?.companyName || 'Your Company';
  const position = ctx?.position || 'Position';
  const lang = ctx?.lang || els.lang.value || 'de';
  return `You are Clarity's interview agent for "${companyName}" role "${position}". Use ONLY jobDescription & companyFacts. No web browsing. One concise question/turn, inclusive & unbiased. Reformulate once if needed. No smalltalk. Salary only if provided; else refer to direct discussion. Language: ${lang}.`.trim();
}

// --- Token fetch mit Fallback ---
async function getToken(){
  const payload = {
    uid: els.uid.value.trim(),
    companyId: els.company.value.trim(),
    lang: els.lang.value,
    voice: els.voice.value
  };
  const tryOnce = async (url) => {
    log('Fetching token…', url, JSON.stringify(payload));
    const r = await fetch(url, { method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify(payload) });
    const raw = await r.text();
    log('Token response status:', r.status, 'body:', raw.slice(0, 300));
    let j=null; try{ j=JSON.parse(raw); }catch{}
    return { ok:r.ok && !!j?.token, json:j, status:r.status };
  };

  // 1) bevorzugt /api/wix-token-proxy, 2) fallback /_functions/realtimeToken
  const urls = [els.tokenUrl.value || '/api/wix-token-proxy', '/_functions/realtimeToken'];
  for(const url of urls){
    try{
      const {ok,json,status} = await tryOnce(url);
      if(ok){ modelInUse = json.model; els.pillModel.textContent=`model: ${modelInUse || '—'}`; return json.token; }
      log('token try failed @', url, status, json);
    }catch(e){ log('token fetch error @', url, e.message); }
  }
  throw new Error('token error: all routes failed');
}

async function startLive(){
  try{
    if(pc) await stopLive();
    setState('connecting'); els.start.disabled=true;

    // AudioContext anwerfen (Autoplay-Policy)
    try{
      if(!audioCtx) audioCtx = new (window.AudioContext||window.webkitAudioContext)();
      if(audioCtx.state === 'suspended') await audioCtx.resume();
    }catch(e){ log('audiocontext error', e?.message||e); }

    const token = await getToken();

    // Mic/Kamera
    stream = await navigator.mediaDevices.getUserMedia({
      audio: { echoCancellation:true, noiseSuppression:true },
      video: { width:{ideal:1280}, height:{ideal:720}, frameRate:{ideal:30} }
    });
    els.preview.srcObject = stream;
    log('Cam+Mic ready');

    // Aufnahme (Video+Audio) → Mux
    if(doRecording){
      // Mux endpoint mit Fallback
      const tryMux = async (url) => {
        const up = await fetch(url, { method:'POST' });
        const j = await up.json().catch(()=> ({}));
        return { ok: up.ok && j?.uploadUrl && j?.uploadId, j, status: up.status, url };
      };
      const muxUrls = [els.muxUpload.value || '/api/mux-upload', '/_functions/muxUpload'];
      let init=null;
      for(const u of muxUrls){
        init = await tryMux(u);
        if(init.ok) break;
        log('mux init failed @', u, init.status, init.j);
      }
      if(!init?.ok) throw new Error('mux-upload init failed');
      muxUploadUrl = init.j.uploadUrl; muxUploadId = init.j.uploadId;

      const mime = MediaRecorder.isTypeSupported('video/webm;codecs=vp9,opus') ? 'video/webm;codecs=vp9,opus' : 'video/webm';
      mediaRecorder = new MediaRecorder(stream, { mimeType: mime, videoBitsPerSecond: 3_000_000, audioBitsPerSecond: 128_000 });
      chunks = [];
      mediaRecorder.ondataavailable = e => { if(e.data?.size) chunks.push(e.data); };
      mediaRecorder.onstop = uploadToMux;
      mediaRecorder.start(2000);
      setState('recording'); log('MediaRecorder started (video+audio)');
    }

    // Realtime WebRTC (send Mic, recv Agent)
    pc = new RTCPeerConnection();
    pc.onconnectionstatechange = ()=>{ setState(pc.connectionState); log('pc:', pc.connectionState); };

    // Audio vom Agent
    pc.ontrack = (ev)=> {
      els.audio.srcObject = ev.streams[0];
      const p = els.audio.play(); if(p?.catch) p.catch(()=>{});
      const [track] = ev.streams[0].getAudioTracks();
      log('[live] remote track flags: muted=', track.muted, 'enabled=', track.enabled, 'state=', track.readyState);
    };

    // Mic → Model (sendrecv)
    const audioTrack = stream.getAudioTracks()[0];
    const tx = pc.addTransceiver(audioTrack, { direction:'sendrecv' });
    tx.sender.replaceTrack(audioTrack);

    // DataChannel
    dc = pc.createDataChannel('oai-events');
    dc.onopen = onDataChannelOpen;
    dc.onmessage = onAgentEvent;
    dc.onclose = ()=> log('DataChannel closed');
    dc.onerror = (e)=> log('DataChannel error', e?.message||e);

    // Offer → OpenAI Realtime
    const offer = await pc.createOffer();
    await pc.setLocalDescription(offer);
    const model = modelInUse || 'gpt-4o-realtime-preview';
    const rt = await fetch(`https://api.openai.com/v1/realtime?model=${encodeURIComponent(model)}`, {
      method:'POST',
      headers:{
        Authorization:`Bearer ${token}`,
        'Content-Type':'application/sdp',
        'OpenAI-Beta':'realtime=v1' // wichtig für stabile Audio-Sitzung
      },
      body: offer.sdp
    });
    if(!rt.ok){
      const msg = await rt.text().catch(()=>null);
      throw new Error(`Realtime SDP error ${rt.status} ${msg||''}`);
    }
    const answerSdp = await rt.text();
    await pc.setRemoteDescription({ type:'answer', sdp: answerSdp });
    setState('connected'); log('Realtime connected');

    // Startprompt
    if(dc && dc.readyState==='open'){
      dc.send(JSON.stringify({ type:'session.update', session:{ voice: els.voice.value, modalities:['audio','text'], instructions: buildSystemInstructions({ lang: els.lang.value }) }}));
      // Erste Audio+Text Probe — serialisiert
      createResponseSafe({ modalities:['audio','text'], voice: els.voice.value, instructions:'Sag bitte genau: TESTTEST. Danach zähle 1 2 3.' });
      // Danach Text-only-Probe
      queuedResponsePayload = { modalities:['text'], instructions:'TEXT-ONLY-PROBE: Schreibe genau "TEXT-OK".' };
    }
    parentPost({ type:'clarity.avatar', data:{ state:'speaking' } });

  }catch(e){
    log('startLive error:', e.message);
    setState('error');
  }finally{
    els.start.disabled=false;
  }
}

// Serialisierte response.create
function createResponseSafe(payload){
  if(!dc || dc.readyState!=='open') return;
  if(activeResponseId){
    queuedResponsePayload = payload;
    log('[rt] queued response.create until current finishes');
    return;
  }
  dc.send(JSON.stringify({ type:'response.create', response: payload }));
  log('[rt] response.create sent', JSON.stringify(payload));
}

function onDataChannelOpen(){
  log('DataChannel open');
  // Session-Settings werden in startLive gesetzt
}

function onAgentEvent(ev){
  try{
    const msg = JSON.parse(ev.data);
    log('[rt] event', msg.type || '', JSON.stringify(msg));

    if (msg?.type === 'error') {
      log('[rt] ERROR', JSON.stringify(msg.error));
    }
    if (msg?.type === 'response.created') {
      activeResponseId = msg?.response?.id || null;
    }
    if (msg?.type==='response.output_text.delta' && msg?.delta){
      els.text.value += msg.delta;
      els.text.scrollTop = els.text.scrollHeight;
    }
    if (msg?.type==='response.delta' && msg?.delta){
      els.text.value += msg.delta;
      els.text.scrollTop = els.text.scrollHeight;
    }
    if (msg?.type==='response.completed'){
      els.text.value += '\n';
      parentPost({ type:'clarity.avatar', data:{ state:'listening' } });
    }
    if (msg?.type==='response.done'){
      activeResponseId = null;
      if(queuedResponsePayload){
        const next = queuedResponsePayload; queuedResponsePayload = null;
        setTimeout(()=> createResponseSafe(next), 50);
      }
    }
  }catch{
    els.text.value += (ev.data||'');
  }
}

async function stopLive(){
  try{
    setState('closing');
    if(mediaRecorder && mediaRecorder.state!=='inactive'){ mediaRecorder.stop(); }
    if(dc){ try{ dc.close(); }catch{} }
    if(pc){ try{ pc.close(); }catch{} }
    if(stream){ stream.getTracks().forEach(t=>t.stop()); }
  }catch(e){
    log('stopLive error:', e.message);
  }finally{
    dc=null; pc=null; stream=null; mediaRecorder=null;
    activeResponseId=null; queuedResponsePayload=null;
    setState('idle');
    parentPost({ type:'clarity.avatar', data:{ state:'idle' } });
  }
}

async function uploadToMux(){
  try{
    setState('uploading');
    const blob = new Blob(chunks, { type: chunks[0]?.type || 'video/webm' });
    const r = await fetch(muxUploadUrl, { method:'PUT', headers:{ 'Content-Type':'application/octet-stream' }, body: blob });
    if(!r.ok) throw new Error('Mux direct upload failed');
    log('Mux upload OK, uploadId:', muxUploadId);
    parentPost({ type:'mux.upload.done', data:{ uploadId: muxUploadId } });
  }catch(err){
    log('uploadToMux error:', err.message);
    parentPost({ type:'mux.upload.error', data:{ message: err.message } });
  }finally{
    setState('connected');
  }
}

function parentPost(msg){ try{ window.parent?.postMessage(msg,'*'); }catch{} }
</script>
</body>
</html>
