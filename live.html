<!-- pages/User Interview (Live geführtes Gespräch + Audio-Only Fallback) — v2.4 -->
<!doctype html>
<html lang="de">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>CLARITY Interview</title>
  <style>
    :root { --bg:#0b0f1a; --card:#111729; --muted:#6b7280; --ok:#10b981; --warn:#f59e0b; --err:#ef4444; --txt:#e5e7eb; }
    html,body{height:100%}
    body{margin:0;background:var(--bg);color:var(--txt);font:14px/1.4 system-ui,Segoe UI,Roboto,Arial,sans-serif;display:flex;align-items:center;justify-content:center}
    .wrap{width:min(960px,94vw);padding:20px}
    .card{background:var(--card);border-radius:16px;box-shadow:0 10px 30px rgba(0,0,0,.35);padding:18px 18px 14px}
    h1{font-size:20px;margin:0 0 8px 0}
    .row{display:grid;grid-template-columns:1fr 320px;gap:16px}
    video,.audiobar{width:100%;border-radius:12px;background:#000}
    .btn{display:inline-flex;gap:8px;align-items:center;border:1px solid #2b3550;background:#16213a;color:#dbeafe;border-radius:10px;padding:10px 14px;cursor:pointer}
    .btn[disabled]{opacity:.5;cursor:not-allowed}
    .muted{color:var(--muted)}
    .status{font-family:ui-monospace,Consolas,monospace;font-size:12px;background:#0e1525;border:1px solid #1b2540;border-radius:10px;padding:10px;min-height:44px;white-space:pre-wrap}
    .pill{display:inline-block;padding:2px 8px;border-radius:999px;font-size:12px;border:1px solid #2b3550;background:#0f1a31}
    .hidden{display:none !important}
    .success{color:var(--ok)}
    .warn{color:var(--warn)}
    .err{color:var(--err)}
    .sp{height:10px}
  </style>
</head>
<body>
<div class="wrap">
  <div class="card">
    <h1>CLARITY Interview</h1>

    <div class="row">
      <div>
        <video id="preview" playsinline autoplay muted></video>
        <div class="sp"></div>
        <audio id="agentAudio" autoplay></audio>
        <div class="sp"></div>
        <div class="status" id="log"></div>
      </div>
      <div>
        <div style="display:flex;gap:8px;flex-wrap:wrap">
          <button id="btnStart" class="btn">▶ Start</button>
          <button id="btnStop" class="btn" disabled>■ Stop</button>
          <button id="btnFinish" class="btn" disabled>⏹ Interview abschließen</button>
          <span id="state" class="pill">idle</span>
        </div>
        <div class="sp"></div>
        <div class="status" id="meta"></div>
      </div>
    </div>
  </div>
</div>

<script>
(() => {
  // ======= Query & Globals =======
  const qp = new URLSearchParams(location.search);
  const linkId = qp.get('uid') || qp.get('linkId') || '';
  const companyId = qp.get('companyId') || '';
  const model = 'gpt-4o-realtime-preview'; // stabiler Name
  const els = {
    video: document.getElementById('preview'),
    agent: document.getElementById('agentAudio'),
    btnStart: document.getElementById('btnStart'),
    btnStop: document.getElementById('btnStop'),
    btnFinish: document.getElementById('btnFinish'),
    log: document.getElementById('log'),
    meta: document.getElementById('meta'),
    state: document.getElementById('state'),
  };

  // Interview State Machine
  const State = Object.freeze({
    Idle:'idle', Greeting:'greeting', Q:'q', Closing:'closing',
    Finalize:'finalize', Rating:'rating', Done:'done'
  });
  let currentState = State.Idle;
  function setState(s){
    currentState = s; els.state.textContent = s;
    log(`STATE → ${s}`);
  }

  // Media / WebRTC
  let pc, dc, stream = null;           // local (mic+cam) stream
  let mediaRecorder = null, chunks = [];
  let remoteAudioStream = null;        // agent voice (remote)
  let audioCtx = null, micSrc = null, agentSrc = null, mixDest = null, mixedStream = null;

  // Session / Server
  let sessionId = null;                // generated server-side
  let uploadUrl = null;                // Mux direct upload URL
  let uploadId = null;                 // Mux upload id
  let voice = null, userCommLang = null, reportLang = null, roleProfile = null, mode = null;

  // ======= Helpers =======
  const log = (t) => { els.log.textContent = (els.log.textContent + `\n${t}`).trim(); };
  const setMeta = (obj) => { els.meta.textContent = JSON.stringify(obj, null, 2); };
  const wait = (ms) => new Promise(r=>setTimeout(r,ms));

  async function ensureMedia(){
    if (stream) return stream;
    // mode from Access (video|audio)
    const wantVideo = (mode || 'video') === 'video';
    stream = await navigator.mediaDevices.getUserMedia({
      audio: { echoCancellation:true, noiseSuppression:true },
      video: wantVideo ? { width:{ideal:1280}, height:{ideal:720} } : false
    });
    els.video.srcObject = stream;
    els.video.muted = true;
    await els.video.play().catch(()=>{});
    return stream;
  }

  function buildMixedStream() {
    if (!stream || !remoteAudioStream) return null;
    if (!audioCtx) audioCtx = new (window.AudioContext || window.webkitAudioContext)();

    if (!micSrc)   micSrc   = audioCtx.createMediaStreamSource(stream);
    if (!agentSrc) agentSrc = audioCtx.createMediaStreamSource(remoteAudioStream);
    mixDest = audioCtx.createMediaStreamDestination();

    const micGain = audioCtx.createGain();   micGain.gain.value = 1.0;
    const botGain = audioCtx.createGain();   botGain.gain.value = 0.85;

    micSrc.connect(micGain).connect(mixDest);
    agentSrc.connect(botGain).connect(mixDest);

    mixedStream = new MediaStream([
      ...mixDest.stream.getAudioTracks(),
      ...stream.getVideoTracks()
    ]);
    return mixedStream;
  }

  function startRecorder(){
    chunks = [];
    const ms = buildMixedStream() || stream;
    const mime = MediaRecorder.isTypeSupported('video/webm;codecs=vp9,opus')
      ? 'video/webm;codecs=vp9,opus'
      : 'video/webm';
    mediaRecorder = new MediaRecorder(ms, {
      mimeType: mime,
      videoBitsPerSecond: 3_000_000,
      audioBitsPerSecond: 128_000
    });
    mediaRecorder.ondataavailable = (e)=>{ if(e.data?.size) chunks.push(e.data); };
    mediaRecorder.onstop = async () => {
      try {
        const blob = new Blob(chunks, { type: mime });
        log(`Recorder stopped. Size=${blob.size}`);
        if (!uploadUrl) {
          log('No upload URL present, requesting…');
          await getMuxUploadUrl(); // safety
        }
        await directUploadToMux(uploadUrl, blob);
      } catch (e) {
        log(`Upload error: ${e.message}`);
      }
    };
    mediaRecorder.start(1000);
    log('Recorder started.');
  }

  async function stopRecorder(){
    if (mediaRecorder && mediaRecorder.state !== 'inactive') mediaRecorder.stop();
  }

  // ======= Server Calls =======
  async function initSession(){
    const res = await fetch('/_functions/interview/init', {
      method:'POST',
      headers:{'Content-Type':'application/json'},
      body: JSON.stringify({ linkId, companyId })
    });
    if (!res.ok) throw new Error('init failed');
    const data = await res.json();
    sessionId = data.sessionId;
    voice = data.voice;
    userCommLang = data.userCommLang;
    reportLang = data.reportLang;
    roleProfile = data.roleProfile;
    mode = data.mode;
    setMeta({ sessionId, voice, userCommLang, reportLang, roleProfile, mode });
  }

  async function getRealtimeToken(){
    const res = await fetch('/_functions/realtimeToken', {
      method:'POST', headers:{'Content-Type':'application/json'},
      body: JSON.stringify({ linkId, companyId, sessionId })
    });
    if (!res.ok) throw new Error('token failed');
    return await res.json(); // {client_secret:{value}, model, voice}
  }

  async function getMuxUploadUrl(){
    const res = await fetch('/_functions/mux/direct-upload', {
      method:'POST', headers:{'Content-Type':'application/json'},
      body: JSON.stringify({ sessionId, linkId, companyId })
    });
    if (!res.ok) throw new Error('mux url failed');
    const data = await res.json();
    uploadUrl = data.uploadUrl;
    uploadId = data.uploadId;
    log(`Mux upload ready: ${uploadId}`);
  }

  async function directUploadToMux(url, blob){
    log('Uploading to Mux…');
    const r = await fetch(url, { method:'PUT', body: blob });
    if (!r.ok) throw new Error(`Mux upload ${r.status}`);
    log('Mux upload complete.');
    // notify backend
    await fetch('/_functions/interview/upload-complete', {
      method:'POST', headers:{'Content-Type':'application/json'},
      body: JSON.stringify({ sessionId, linkId, companyId, uploadId })
    });
  }

  async function finalizeReport(){
    const r = await fetch('/_functions/report/finalize', {
      method:'POST', headers:{'Content-Type':'application/json'},
      body: JSON.stringify({ sessionId, linkId, companyId })
    });
    if (!r.ok) throw new Error('finalize failed');
    const data = await r.json();
    log(`Report ready: ${data.reportPdfUrl || '(pending asset.ready)'}`);
  }

  // ======= Realtime (WebRTC) =======
  async function startLive(){
    await ensureMedia();
    await initSession();
    const token = await getRealtimeToken();
    await getMuxUploadUrl();

    pc = new RTCPeerConnection();
    dc = pc.createDataChannel('commands');

    // remote audio (Agent)
    pc.ontrack = (ev) => {
      remoteAudioStream = ev.streams[0];
      els.agent.srcObject = remoteAudioStream;
      els.agent.play().catch(()=>{});
      log('Remote audio track attached.');
    };

    // publish mic+cam
    stream.getTracks().forEach(t => pc.addTrack(t, stream));

    // SDP Offer → Realtime API
    const offer = await pc.createOffer();
    await pc.setLocalDescription(offer);

    const sdpRes = await fetch('https://api.openai.com/v1/realtime?model=' + encodeURIComponent(model), {
      method:'POST',
      body: offer.sdp,
      headers:{
        'Authorization': 'Bearer ' + token.client_secret.value,
        'Content-Type':'application/sdp'
      }
    });
    const answer = { type:'answer', sdp: await sdpRes.text() };
    await pc.setRemoteDescription(answer);

    // start recording after remote track ready
    setTimeout(()=> startRecorder(), 500);

    // Kickoff Greeting
    setState(State.Greeting);
    dc.onopen = () => {
      dc.send(JSON.stringify({
        type:'system',
        op:'start',
        payload:{
          sessionId, linkId, companyId,
          voice: token.voice,
          userCommLang, reportLang,
          roleProfile,
          flow:'interview-7q+2fup'
        }
      }));
      setState(State.Q);
    };
  }

  async function stopLive(){
    await stopRecorder();
    if (dc && dc.readyState === 'open') dc.close();
    if (pc) { pc.getSenders().forEach(s=>s.track?.stop()); pc.close(); }
    log('Live stopped.');
  }

  // ======= UI Buttons =======
  els.btnStart.onclick = async () => {
    els.btnStart.disabled = true;
    els.btnStop.disabled = false;
    els.btnFinish.disabled = false;
    try {
      await startLive();
    } catch (e) {
      log('Start error: ' + e.message);
      els.btnStart.disabled = false;
      els.btnStop.disabled = true;
      els.btnFinish.disabled = true;
    }
  };

  els.btnStop.onclick = async () => {
    els.btnStop.disabled = true;
    await stopLive();
  };

  els.btnFinish.onclick = async () => {
    els.btnFinish.disabled = true;
    setState(State.Finalize);
    await stopLive();
    await finalizeReport(); // erzeugt/verkettet PDF nach asset.ready
    setState(State.Rating);
    // UI: hier Rating einblenden (optional)
    setState(State.Done);
  };

  // Autoplay unlock on gesture
  window.addEventListener('click', async () => {
    try { await els.agent.play(); } catch {}
    if (audioCtx && audioCtx.state === 'suspended') audioCtx.resume();
  }, { once:true });

})();
</script>
</body>
</html>
