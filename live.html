<!doctype html>
<html lang="de">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width,initial-scale=1"/>
  <title>Clarity Live (Realtime + Recording → Mux)</title>
  <style>
    :root{--bg:#0b0d12;--fg:#e5e7eb;--muted:#9ca3af;--accent:#60a5fa}
    body{margin:0;font-family:ui-sans-serif,system-ui,Segoe UI,Roboto,Arial;background:var(--bg);color:var(--fg)}
    .wrap{max-width:860px;margin:0 auto;padding:16px}
    h1{font-size:18px;margin:0 0 12px}
    .card{background:#0f1320;border:1px solid #1f2937;border-radius:14px;padding:14px;box-shadow:0 10px 30px rgba(0,0,0,.25)}
    .row{display:flex;gap:10px;align-items:center;flex-wrap:wrap}
    button,input,select{background:#0b1220;color:var(--fg);border:1px solid #303b4a;border-radius:10px;padding:10px 12px}
    button.primary{background:linear-gradient(135deg,#2563eb,#0ea5e9);border:none}
    button:disabled{opacity:.6;cursor:not-allowed}
    video{width:220px;height:140px;background:#000;border-radius:10px;object-fit:cover}
    .pill{display:inline-block;padding:4px 10px;border-radius:999px;background:#0b1220;border:1px solid #303b4a;font-size:12px}
    .muted{opacity:.75}
    .sr{position:absolute;left:-9999px}
    .log{display:none} /* im UI versteckt, aber wir loggen in console */
  </style>
</head>
<body>
  <div class="wrap">
    <h1>Clarity Live</h1>

    <div class="card">
      <div class="row">
        <button id="btnStart" class="primary">Start</button>
        <button id="btnStop">Stop</button>
        <span id="pillState" class="pill">state: idle</span>
        <span id="pillRec" class="pill">record: on</span>
        <label class="sr" for="selVoice">Voice</label>
        <select id="selVoice" title="Voice">
          <option value="verse" selected>verse</option>
          <option value="alloy">alloy</option>
          <option value="ash">ash</option>
          <option value="ballad">ballad</option>
          <option value="coral">coral</option>
          <option value="echo">echo</option>
          <option value="sage">sage</option>
          <option value="shimmer">shimmer</option>
        </select>
      </div>

      <div class="row" style="margin-top:10px">
        <div>
          <div class="muted" style="font-size:12px;margin-bottom:6px">Kamera-Vorschau</div>
          <video id="preview" autoplay playsinline muted></video>
        </div>
        <audio id="agentAudio" class="sr" autoplay></audio>
      </div>
    </div>

    <pre id="log" class="log"></pre>
  </div>

<script>
(() => {
/* ---------- Elements ---------- */
const els = {
  start: q('#btnStart'),
  stop: q('#btnStop'),
  preview: q('#preview'),
  agentAudio: q('#agentAudio'),
  pillState: q('#pillState'),
  pillRec: q('#pillRec'),
  voice: q('#selVoice'),
  log: q('#log'),
};
function q(s){ return document.querySelector(s); }
function setState(s){ els.pillState.textContent = 'state: ' + s; }
function log(...a){
  const line = a.map(v => typeof v==='string' ? v : JSON.stringify(v)).join(' ');
  console.log(line);
}

/* ---------- Config (endpoints) ---------- */
const TOKEN_URL = '/_functions/realtimeToken';
const MUX_UPLOAD_URL = '/_functions/muxUpload';

/* ---------- Realtime / Media globals ---------- */
let pc = null, dc = null, stream = null, mediaRecorder = null, chunks = [];
let muxUploadUrl = null, muxUploadId = null;
let modelInUse = 'gpt-4o-realtime-preview';
let doRecording = true;

els.start.onclick = startAll;
els.stop.onclick = stopAll;

async function startAll(){
  els.start.disabled = true;
  try{
    setState('init');

    // 1) Token vom Backend
    const { token, model } = await fetchToken({ voice: els.voice.value });
    modelInUse = model || modelInUse;
    log('[token] ok, model:', modelInUse);

    // 2) Mic + Cam (Preview, plus Audio für Realtime)
    stream = await navigator.mediaDevices.getUserMedia({
      audio: { echoCancellation:true, noiseSuppression:true },
      video: { width:{ideal:1280}, height:{ideal:720}, frameRate:{ideal:30} }
    });
    els.preview.srcObject = stream;
    log('[media] mic+cam ready');

    // 3) Mux Direct Upload initialisieren
    await initMuxUpload();
    // 4) Recorder starten
    startRecorder(stream);

    // 5) Realtime (Audio ↔︎ Model)
    await startRealtime(token, modelInUse);

    setState('connected');
  }catch(e){
    log('[startAll error]', e.message||e);
    setState('error');
  }finally{
    els.start.disabled = false;
  }
}

async function stopAll(){
  setState('stopping');

  // Stop Recorder → onstop -> uploadToMux()
  try{ if(mediaRecorder && mediaRecorder.state!=='inactive') mediaRecorder.stop(); }catch{}

  // Realtime
  try{ dc && dc.close(); }catch{}
  try{ pc && pc.close(); }catch{}
  dc = null; pc = null;

  // Media
  try{ if(stream){ stream.getTracks().forEach(t=>t.stop()); } }catch{}

  setState('idle');
}

/* ---------- Token ---------- */
async function fetchToken({ voice }){
  const r = await fetch(TOKEN_URL, {
    method:'POST',
    headers:{ 'Content-Type':'application/json' },
    body: JSON.stringify({ voice })
  });
  const j = await r.json().catch(()=> ({}));
  if(!r.ok || !j?.ok || !j?.token) throw new Error('token fetch failed');
  return { token: j.token, model: j.model };
}

/* ---------- Mux ---------- */
async function initMuxUpload(){
  const r = await fetch(MUX_UPLOAD_URL, { method:'POST' });
  const j = await r.json().catch(()=> ({}));
  if(!r.ok || !j?.ok || !j?.uploadUrl || !j?.uploadId) throw new Error('mux init failed');
  muxUploadUrl = j.uploadUrl; muxUploadId = j.uploadId;
  log('[mux] direct upload prepared', muxUploadId);
}

/* ---------- Recorder ---------- */
function startRecorder(stream){
  if(!doRecording){ els.pillRec.textContent = 'record: off'; return; }
  els.pillRec.textContent = 'record: on';
  const mime = MediaRecorder.isTypeSupported('video/webm;codecs=vp9,opus') ? 'video/webm;codecs=vp9,opus' : 'video/webm';
  mediaRecorder = new MediaRecorder(stream, {
    mimeType: mime,
    videoBitsPerSecond: 3_000_000,
    audioBitsPerSecond: 128_000
  });
  chunks = [];
  mediaRecorder.ondataavailable = (e)=>{ if(e.data?.size) chunks.push(e.data); };
  mediaRecorder.onstop = uploadToMux;
  mediaRecorder.start(2000);
  setState('recording');
  log('[recorder] started', mime);
}

async function uploadToMux(){
  try{
    setState('uploading');
    const blob = new Blob(chunks, { type: chunks[0]?.type || 'video/webm' });
    const r = await fetch(muxUploadUrl, {
      method:'PUT',
      headers:{ 'Content-Type':'application/octet-stream' },
      body: blob
    });
    if(!r.ok) throw new Error('mux direct upload failed');
    log('[mux] uploaded ok', muxUploadId);
  }catch(e){
    log('[mux upload error]', e.message||e);
  }finally{
    setState('idle');
  }
}

/* ---------- Realtime ---------- */
async function startRealtime(token, model){
  setState('webrtc');
  pc = new RTCPeerConnection();

  // remote agent audio
  pc.ontrack = (ev) => {
    els.agentAudio.srcObject = ev.streams[0];
    const play = els.agentAudio.play();
    if(play?.catch) play.catch(()=>{ /* ignore autoplay block (hidden) */ });
    const [track] = ev.streams[0].getAudioTracks();
    log('[live] remote track flags: muted=', track.muted, 'enabled=', track.enabled, 'state=', track.readyState);
  };

  // send microphone to model, receive model audio back
  const mic = stream.getAudioTracks()[0];
  const tx = pc.addTransceiver(mic, { direction: 'sendrecv' });
  await tx.sender.replaceTrack(mic);

  // DC
  const channel = pc.createDataChannel('oai-events');
  dc = channel;
  dc.onopen = () => {
    log('[dc] open');
    dc.send(JSON.stringify({ type:'session.update', session:{ voice: els.voice.value, modalities:['audio','text'] }}));
    // kleiner Hörtest (kurz & harmlos)
    dc.send(JSON.stringify({ type:'response.create', response:{ modalities:['audio','text'], instructions:'Sag bitte genau: TESTTEST. Danach zähle 1 2 3.' }}));
  };
  dc.onmessage = (ev) => {
    try{
      const msg = JSON.parse(ev.data);
      if(msg?.type === 'response.done' && msg?.response?.status === 'failed'){
        log('[rt fail]', JSON.stringify(msg.response.status_details));
      }
    }catch{}
  };

  const offer = await pc.createOffer();
  await pc.setLocalDescription(offer);

  const sdpResp = await fetch(`https://api.openai.com/v1/realtime?model=${encodeURIComponent(model)}`, {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${token}`,
      'Content-Type': 'application/sdp',
      'OpenAI-Beta': 'realtime=v1'
    },
    body: offer.sdp
  });

  if(!sdpResp.ok){
    const t = await sdpResp.text().catch(()=>null);
    throw new Error('SDP answer error ' + sdpResp.status + ' ' + t);
  }

  const answer = await sdpResp.text();
  await pc.setRemoteDescription({ type:'answer', sdp: answer });
  log('[webrtc] connected');
}
})();
</script>
</body>
</html>
