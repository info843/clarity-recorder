<!-- /live.html — Vercel A/V iframe (patched to use Wix _functions via ?api=) -->
<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>CLARITY Live Interview</title>
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <style>
    html,body{margin:0;padding:0;background:#000;color:#9ca3af;font:12px system-ui,Segoe UI,Roboto,Arial,sans-serif}
    video{width:1px;height:1px;position:absolute;left:-9999px;opacity:0} /* camera preview hidden (iframe only) */
    audio{display:none}
  </style>
</head>
<body>
  <video id="local" playsinline autoplay muted></video>
  <audio id="agent" autoplay></audio>

<script>
(() => {
  // ===== Query Params =====
  const qp = new URLSearchParams(location.search);
  const uid        = qp.get('uid') || qp.get('linkId') || '';
  const companyId  = qp.get('companyId') || '';
  const userLang   = (qp.get('lang') || 'de').toLowerCase();
  const voiceHint  = qp.get('voice') || '';        // optional preferred voice
  const roleHint   = qp.get('role')  || '';        // optional role/profile
  const flowHint   = qp.get('flow')  || '7q+2fup'; // interview structure hint
  // IMPORTANT: all Wix HTTP functions are called through this base (fixes 404 on Vercel)
  const API_BASE   = qp.get('api') || 'https://www.clarity-nvl.com';

  // ===== DOM =====
  const els = {
    video: document.getElementById('local'),
    agent: document.getElementById('agent')
  };

  // ===== State =====
  const MODEL = 'gpt-4o-realtime-preview';
  let pc = null, dc = null;
  let localStream = null;
  let remoteAudioStream = null;
  let mediaRecorder = null, chunks = [];
  let uploadUrl = null, uploadId = null;
  let sessionId = null;
  let audioCtx = null, micSrc = null, agentSrc = null, mixDest = null, mixedStream = null;
  let recordEnabled = false;
  let started = false;

  // ===== PostMessage helpers =====
  function post(type, data){ try{ parent.postMessage(JSON.stringify({ type, data }), '*'); }catch(_){/*noop*/} }
  function signalError(message){ post('clarity.error', { message }); }

  // ===== Media =====
  async function ensureMedia(){
    if (localStream) return localStream;
    const withVideo = true; // full live mode; audio-only fallback lives in different iframe (recorder.html)
    localStream = await navigator.mediaDevices.getUserMedia({
      audio:{ echoCancellation:true, noiseSuppression:true },
      video: withVideo ? { width:{ideal:1280}, height:{ideal:720} } : false
    });
    els.video.srcObject = localStream;
    els.video.muted = true;
    try { await els.video.play(); } catch(_){}
    return localStream;
  }

  function buildMixedStream() {
    if (!localStream || !remoteAudioStream) return null;
    if (!audioCtx) audioCtx = new (window.AudioContext || window.webkitAudioContext)();

    if (!micSrc)   micSrc   = audioCtx.createMediaStreamSource(localStream);
    if (!agentSrc) agentSrc = audioCtx.createMediaStreamSource(remoteAudioStream);
    mixDest = audioCtx.createMediaStreamDestination();

    const micGain = audioCtx.createGain();   micGain.gain.value = 1.0;
    const botGain = audioCtx.createGain();   botGain.gain.value = 0.85;

    micSrc.connect(micGain).connect(mixDest);
    agentSrc.connect(botGain).connect(mixDest);

    mixedStream = new MediaStream([
      ...mixDest.stream.getAudioTracks(),
      ...localStream.getVideoTracks()
    ]);
    return mixedStream;
  }

  function startRecorder(){
    try{
      if (!recordEnabled) return;
      chunks = [];
      const ms = buildMixedStream() || localStream;
      const mime = MediaRecorder.isTypeSupported('video/webm;codecs=vp9,opus')
        ? 'video/webm;codecs=vp9,opus'
        : 'video/webm';
      mediaRecorder = new MediaRecorder(ms, {
        mimeType: mime,
        videoBitsPerSecond: 3_000_000,
        audioBitsPerSecond: 128_000
      });
      mediaRecorder.ondataavailable = (e)=>{ if(e.data && e.data.size) chunks.push(e.data); };
      mediaRecorder.onstop = async () => {
        try{
          const blob = new Blob(chunks, { type: mime });
          if (!uploadUrl) await getMuxUploadUrl();
          await directUploadToMux(uploadUrl, blob);
          post('mux.upload.done', { uploadId });
        }catch(e){
          signalError('Upload error: ' + e.message);
          post('mux.upload.error', { message: e.message });
        }
      };
      mediaRecorder.start(1000);
    }catch(e){
      signalError('Recorder start failed: ' + e.message);
    }
  }

  async function stopRecorder(){
    try{
      if (mediaRecorder && mediaRecorder.state !== 'inactive') mediaRecorder.stop();
    }catch(_){}
  }

  // ===== Backend calls (Wix HTTP functions via API_BASE) =====
  async function initSession(){
    // Prefer your existing page calling startSession; this is fallback if called from here
    const res = await fetch(`${API_BASE}/_functions/interview/init`, {
      method:'POST',
      headers:{ 'Content-Type':'application/json' },
      body: JSON.stringify({ linkId: uid, companyId })
    });
    if (!res.ok) throw new Error('init failed ' + res.status);
    const data = await res.json(); // { ok, sessionId, ... }
    if (data?.sessionId) sessionId = data.sessionId;
    return data;
  }

  async function getRealtimeToken(){
    const res = await fetch(`${API_BASE}/_functions/realtimeToken`, {
      method:'POST',
      headers:{ 'Content-Type':'application/json' },
      body: JSON.stringify({ linkId: uid, companyId, sessionId })
    });
    if (!res.ok) throw new Error('token failed ' + res.status);
    return await res.json(); // {client_secret:{value}, model, voice}
  }

  async function getMuxUploadUrl(){
    const res = await fetch(`${API_BASE}/_functions/mux/direct-upload`, {
      method:'POST',
      headers:{ 'Content-Type':'application/json' },
      body: JSON.stringify({ sessionId, linkId: uid, companyId })
    });
    if (!res.ok) throw new Error('mux url failed ' + res.status);
    const data = await res.json(); // { uploadUrl, uploadId }
    uploadUrl = data.uploadUrl;
    uploadId  = data.uploadId;
  }

  async function notifyUploadComplete(){
    try{
      await fetch(`${API_BASE}/_functions/interview/upload-complete`, {
        method:'POST',
        headers:{ 'Content-Type':'application/json' },
        body: JSON.stringify({ sessionId, linkId: uid, companyId, uploadId })
      });
    }catch(_){}
  }

  async function directUploadToMux(url, blob){
    const r = await fetch(url, { method:'PUT', body: blob });
    if (!r.ok) throw new Error(`Mux upload ${r.status}`);
    await notifyUploadComplete();
  }

  // ===== WebRTC (OpenAI Realtime) =====
  async function startLive(){
    if (started) return;
    started = true;

    // 0) Media
    await ensureMedia();

    // 1) Ensure sessionId (either page already created it, or fallback here)
    if (!sessionId){
      try { const x = await initSession(); sessionId = x?.sessionId || sessionId; } catch(e){ signalError(e.message); }
    }
    if (!sessionId){ signalError('No sessionId'); return; }

    // 2) Token & Mux upload url
    const token = await getRealtimeToken();
    await getMuxUploadUrl();

    // 3) RTCPeerConnection
    pc = new RTCPeerConnection();
    dc = pc.createDataChannel('commands');

    // remote audio
    pc.ontrack = (ev) => {
      remoteAudioStream = ev.streams[0];
      els.agent.srcObject = remoteAudioStream;
      els.agent.play?.().catch(()=>{});
      post('clarity.avatar', { state:'speaking' });
      setTimeout(()=> post('clarity.avatar', { state:'listening' }), 800);
      // start recorder when remote audio available & record enabled
      setTimeout(() => startRecorder(), 400);
    };

    // publish local tracks
    localStream.getTracks().forEach(tr => pc.addTrack(tr, localStream));

    // 4) Offer → Realtime
    const offer = await pc.createOffer();
    await pc.setLocalDescription(offer);

    const res = await fetch('https://api.openai.com/v1/realtime?model=' + encodeURIComponent(MODEL), {
      method:'POST',
      body: offer.sdp,
      headers:{
        'Authorization': 'Bearer ' + token?.client_secret?.value,
        'Content-Type':'application/sdp'
      }
    });
    if (!res.ok) throw new Error('Realtime SDP failed ' + res.status);
    const answer = { type:'answer', sdp: await res.text() };
    await pc.setRemoteDescription(answer);

    // 5) DataChannel – optional control
    dc.onopen = () => {
      // pass hints (role/lang/flow/voice) so your server prompt can adapt
      try{
        dc.send(JSON.stringify({
          type:'system',
          op:'context',
          payload:{
            sessionId, uid, companyId,
            lang: userLang,
            role: roleHint,
            flow: flowHint,
            voice: voiceHint
          }
        }));
      }catch(_){}
    };
    dc.onclose = () => { post('clarity.avatar', { state:'idle' }); };
  }

  async function stopLive(){
    try{ await stopRecorder(); }catch(_){}
    try{ if (dc && dc.readyState === 'open') dc.close(); }catch(_){}
    try{ if (pc){ pc.getSenders().forEach(s=>s.track?.stop()); pc.close(); } }catch(_){}
    post('clarity.avatar', { state:'idle' });
  }

  // ===== Message bridge (parent → iframe) =====
  window.addEventListener('message', async (ev) => {
    let msg = ev?.data;
    try { if (typeof msg === 'string') msg = JSON.parse(msg); } catch(_){}
    const type = msg?.type;
    const data = msg?.data || {};

    if (type === 'clarity.live.context'){
      // not strictly needed here; context is also sent via DC when open
      // keep for future local display
      return;
    }
    if (type === 'clarity.live.record'){
      recordEnabled = !!(data && data.enabled);
      return;
    }
    if (type === 'clarity.live.start'){
      try{
        // user gesture unlock for autoplay
        try { await els.agent.play(); } catch(_){}
        if (audioCtx && audioCtx.state === 'suspended') { try{ await audioCtx.resume(); }catch(_){} }
        await startLive();
      }catch(e){
        signalError(e.message);
      }
      return;
    }
    if (type === 'clarity.live.stop'){
      await stopLive();
      return;
    }
  });

  // Announce ready to parent
  post('clarity.live.ready', { ok:true });

  // Unlock audio on first click (mobile autoplay policies)
  window.addEventListener('click', async () => {
    try { await els.agent.play(); } catch(_){}
    if (audioCtx && audioCtx.state === 'suspended') { try{ await audioCtx.resume(); }catch(_){} }
  }, { once:true });

})();
</script>
</body>
</html>
