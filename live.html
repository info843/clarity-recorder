<!doctype html>
<html lang="de">
<head>
  <meta charset="utf-8" />
  <title>Live Interview</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    :root{--bg:#0b0c10;--fg:#e5e7eb;--muted:#9ca3af;--ok:#10b981;--warn:#f59e0b;--err:#ef4444;--card:#111217;--line:#1f2330}
    html,body{margin:0;padding:0;background:var(--bg);color:var(--fg);font:14px/1.45 system-ui,Segoe UI,Roboto,Helvetica,Arial,sans-serif}
    .wrap{display:grid;grid-template-columns:1fr 320px;gap:16px;padding:14px;align-items:start}
    .card{background:var(--card);border:1px solid var(--line);border-radius:12px;padding:12px}
    .row{display:flex;gap:10px;align-items:center}
    .bar{height:6px;background:#0f172a;border-radius:999px;overflow:hidden}
    .bar>i{display:block;height:100%;width:0;background:#4f46e5;transition:width 50ms linear}
    .badge{display:inline-block;padding:2px 6px;border-radius:8px;background:#0f172a;border:1px solid #24314f;color:#cbd5e1;font-size:12px}
    .muted{color:var(--muted)}
    .btn{appearance:none;border:1px solid #2b3244;background:#141827;color:#f8fafc;border-radius:8px;padding:8px 10px;cursor:pointer}
    .btn:disabled{opacity:.5;cursor:not-allowed}
    video{width:100%;max-height:320px;background:#000;border-radius:8px}
    audio{width:100%}
    .grid2{display:grid;grid-template-columns:1fr 1fr;gap:10px}
    .log{font-family:ui-monospace,Menlo,Consolas,monospace;font-size:12px;color:#9ca3af;white-space:pre-wrap;max-height:220px;overflow:auto}
    .ghost{opacity:.65}
  </style>
</head>
<body>
  <div class="wrap">
    <section class="card">
      <div class="row" style="justify-content:space-between">
        <div>
          <div id="status" class="badge">Init…</div>
          <div id="audioBadge" class="badge" style="margin-left:6px">• (stumm?)</div>
        </div>
        <div class="row">
          <button id="btnStop" class="btn">Interview abbrechen</button>
        </div>
      </div>

      <div class="grid2" style="margin-top:12px">
        <div>
          <div class="muted" style="margin-bottom:6px">Kamera-Vorschau</div>
          <video id="localVideo" autoplay playsinline muted></video>
          <div class="muted" style="margin:8px 0 4px">Mic-Level</div>
          <div class="bar"><i id="micLevel"></i></div>
        </div>
        <div>
          <div class="muted" style="margin-bottom:6px">Assistent-Audio</div>
          <audio id="remoteAudio" controls></audio>
          <div class="muted" style="margin:8px 0 4px">System</div>
          <div class="bar"><i id="sysLevel"></i></div>
          <div class="muted" style="margin-top:10px">Hinweis: Bei blockiertem Autoplay ggf. einmal in den Player klicken.</div>
        </div>
      </div>
    </section>

    <aside class="card">
      <div style="font-weight:600;margin-bottom:8px">Recorder / Upload</div>
      <div class="row">
        <div class="badge ghost" id="recState">idle</div>
        <div class="badge ghost" id="upState"  style="margin-left:6px">no upload</div>
      </div>
      <div class="muted" style="margin:8px 0 4px">Fortschritt</div>
      <div class="bar"><i id="recProgress"></i></div>
      <div class="muted" style="margin:10px 0 4px">Logs</div>
      <div id="log" class="log"></div>
    </aside>
  </div>

  <script>
  // -------------------- Query / Kontext --------------------
  const Q = new URLSearchParams(location.search);
  const UID = (Q.get('uid')||'').trim();
  const COMPANY_ID = (Q.get('companyId')||'').trim();
  const LANG = (Q.get('lang')||'de').toLowerCase();        // Sollsprache aus Link / DB
  const VOICE = (Q.get('voice')||'verse').toLowerCase();

  // -------------------- UI Els --------------------
  const $status  = document.getElementById('status');
  const $badge   = document.getElementById('audioBadge');
  const $mic     = document.getElementById('micLevel');
  const $sys     = document.getElementById('sysLevel');
  const $log     = document.getElementById('log');
  const $localV  = document.getElementById('localVideo');
  const $remoteA = document.getElementById('remoteAudio');
  const $btnStop = document.getElementById('btnStop');
  const $recState= document.getElementById('recState');
  const $upState = document.getElementById('upState');
  const $recProg = document.getElementById('recProgress');

  function log(...a){
    console.log(...a);
    const s = a.map(x => typeof x==='object' ? JSON.stringify(x) : String(x)).join(' ');
    $log.textContent += s + "\n";
    $log.scrollTop = $log.scrollHeight;
  }
  function setStatus(kind, text){
    $status.textContent = text || kind || '';
    $status.style.background = kind==='err' ? '#3b0d0d' : (kind==='ok' ? '#0d3b2a' : '#0f172a');
    $status.style.borderColor = kind==='err' ? '#7f1d1d' : (kind==='ok' ? '#14532d' : '#24314f');
  }

  // -------------------- Endpunkte (WICHTIG: feste Domain, NICHT relativ) --------------------
  const WIX_BASE = 'https://www.clarity-nvl.com';
  const TOKEN_URLS = [ `${WIX_BASE}/_functions/realtimeToken` ];
  const WIX_UPLOAD_URL = `${WIX_BASE}/_functions/wixMediaUpload`;

  // -------------------- Global State --------------------
  let pc, DC;
  let localStream, mixedStream, mediaRecorder;
  let remoteStream;
  let audioCtx, remoteSource;

  // ===== DC-Queue + Wait =====
  let dcIsOpen = false;
  let dcQueue = [];
  function dcSend(obj){
    try{
      if (dcIsOpen && DC && DC.readyState === 'open') {
        DC.send(JSON.stringify(obj));
      } else {
        dcQueue.push(obj);
      }
    }catch(e){ console.warn('[RTC] dcSend fail', e); }
  }
  function waitDCOpen(timeoutMs = 5000){
    if (dcIsOpen && DC?.readyState === 'open') return Promise.resolve();
    return new Promise(resolve => {
      const t0 = Date.now();
      const iv = setInterval(() => {
        if (dcIsOpen && DC?.readyState === 'open') {
          clearInterval(iv); resolve();
        } else if (Date.now() - t0 > timeoutMs) {
          clearInterval(iv); resolve();
        }
      }, 50);
    });
  }

  // -------------------- Token --------------------
  async function getRealtimeToken(payload){
    for (const url of TOKEN_URLS){
      try{
        log('[Live] Fetching token…', url, JSON.stringify(payload));
        const r = await fetch(url,{ method:'POST', headers:{'Content-Type':'application/json'}, body:JSON.stringify(payload) });
        if (!r.ok){ const t = await r.text(); log('[Live] Token response:', r.status, t); continue; }
        const data = await r.json().catch(()=> ({}));
        log('[Live] Token response:', r.status, data);
        const sec = extractClientSecret(data);
        if (sec) return { secret: sec, meta: data };
      }catch(e){ log('[Live] token fetch failed', url, e); }
    }
    throw new Error('token_fetch_failed');
  }
  function extractClientSecret(obj){
    if (!obj || typeof obj !== 'object') return null;
    if (typeof obj.client_secret === 'string') return obj.client_secret;
    if (obj.data && typeof obj.data.client_secret === 'string') return obj.data.client_secret;
    if (obj.token && typeof obj.token === 'string') return obj.token;
    if (obj.clientSecret && typeof obj.clientSecret === 'string') return obj.clientSecret;
    return null;
  }

  // -------------------- Realtime WebRTC --------------------
  async function connectRealtime(clientSecret, model='gpt-4o-realtime-preview'){
    pc = new RTCPeerConnection({ iceServers: [{ urls: ['stun:stun.l.google.com:19302'] }] });

    pc.onconnectionstatechange = () => {
      log('[RTC] connected');
      if (pc.connectionState === 'failed' || pc.connectionState === 'disconnected'){
        setStatus('err','Verbindung unterbrochen');
      }
    };

    pc.ontrack = async (ev) => {
      log('[RTC] ontrack kind=', ev.track.kind, 'streams=', ev.streams.length);
      if (!remoteStream) remoteStream = new MediaStream();
      remoteStream.addTrack(ev.track);
      $remoteA.srcObject = remoteStream;

      try{
        audioCtx = audioCtx || new (window.AudioContext || window.webkitAudioContext)();
        await audioCtx.resume().catch(()=>{});
        remoteSource = audioCtx.createMediaStreamSource(remoteStream);
        const analyser = audioCtx.createAnalyser();
        analyser.fftSize = 512;
        const buf = new Uint8Array(analyser.frequencyBinCount);
        remoteSource.connect(analyser);
        (function tick(){
          analyser.getByteTimeDomainData(buf);
          let dev=0; for(let i=0;i<buf.length;i++) dev=Math.max(dev, Math.abs(buf[i]-128));
          $sys.style.width = Math.min(100, dev*2) + '%';
          requestAnimationFrame(tick);
        })();
      }catch(_){}

      try {
        $remoteA.muted = false;
        $remoteA.volume = 1.0;
        $remoteA.setAttribute('autoplay','');
        $remoteA.setAttribute('playsinline','');
        await $remoteA.play();
        log('[RTC] remote audio playing.');
      } catch(e) {
        log('[RTC] play() blocked', e);
        showAudioGate();
      }

      try {
        const levelAnalyser = audioCtx.createAnalyser();
        levelAnalyser.fftSize = 1024;
        remoteSource.connect(levelAnalyser);
        const tbuf = new Uint8Array(levelAnalyser.frequencyBinCount);
        let lastNZ = 0;
        (function ping(){
          levelAnalyser.getByteTimeDomainData(tbuf);
          let dev = 0;
          for (let i=0;i<tbuf.length;i++) dev = Math.max(dev, Math.abs(tbuf[i]-128));
          if (dev>2) lastNZ = performance.now();
          if (performance.now()-lastNZ < 2000) $badge.textContent='• Audio in';
          else $badge.textContent='• (stumm?)';
          requestAnimationFrame(ping);
        })();
      }catch(_){}
    };

    if (localStream){
      localStream.getTracks().forEach(t => pc.addTrack(t, localStream));
    }

    DC = pc.createDataChannel('oai-events');
    DC.onopen = () => {
      dcIsOpen = true;
      log('[RTC] DC open');
      try {
        const pending = dcQueue.splice(0);
        for (const msg of pending) DC.send(JSON.stringify(msg));
      } catch(e){ console.warn('[RTC] flush queue fail', e); }
    };
    DC.onmessage = onRealtimeEvent;

    const offer = await pc.createOffer({ offerToReceiveAudio:true, offerToReceiveVideo:false });
    await pc.setLocalDescription(offer);

    const r = await fetch(`https://api.openai.com/v1/realtime?model=${encodeURIComponent(model)}`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${clientSecret}`,
        'Content-Type': 'application/sdp'
      },
      body: offer.sdp
    });

    if (!r.ok){
      const t = await r.text().catch(()=>r.statusText);
      throw new Error('realtime_handshake_failed: ' + t);
    }

    const answer = { type: 'answer', sdp: await r.text() };
    await pc.setRemoteDescription(answer);
  }

  function onRealtimeEvent(ev){
    let data = ev && ev.data;
    try{ if (typeof data === 'string') data = JSON.parse(data); }catch(_){}
    if (!data) return;
    if (data.type === 'response.state' && data.state){
      parent?.postMessage?.({ type:'clarity.avatar', data:{ state:data.state } }, '*');
    }
  }

  // -------------------- Sprache & Prompts --------------------
  const normLang = (c)=> (String(c||'de').toLowerCase().startsWith('en') ? 'en' : 'de');

  function makeSystemPrompt(L){
    if (L==='de'){
      return [
        'Du bist der Interview-Assistent von Clarity.',
        'Stelle eine Frage nach der anderen. Antworte kurz und präzise.',
        'Sprich AUSSCHLIESSLICH Deutsch. Wechsle NIEMALS die Sprache.',
        'Wenn der Kandidat anders spricht, bleibe auf Deutsch und bitte kurz um Deutsch.',
        '[LANG:DE]'
      ].join(' ');
    }
    return [
      "You are Clarity's interview assistant.",
      'Ask one question at a time. Keep answers short and precise.',
      'Speak STRICTLY in English. NEVER switch languages.',
      'If the candidate uses another language, remain in English and ask them to continue in English.',
      '[LANG:EN]'
    ].join(' ');
  }

  function primeSession(L, voice){
    const sess = {
      voice: voice || 'verse',
      spoken_language: L,
      input_audio_format:'pcm16',
      output_audio_format:'pcm16',
      input_audio_transcription:{ model:'whisper-1', language: L, temperature:0 },
      turn_detection:{ type:'server_vad', threshold:0.9, prefix_padding_ms:200, silence_duration_ms:700 },
      modalities:['audio'],
      voice_language: L,
      tts_language: L,
      instructions: makeSystemPrompt(L),
    };
    dcSend({ type:'session.update', session: sess });
    setTimeout(()=>dcSend({ type:'session.update', session:{ spoken_language:L, input_audio_transcription:{model:'whisper-1',language:L,temperature:0} }}), 150);
    setTimeout(()=>dcSend({ type:'session.update', session:{ spoken_language:L } }), 400);
  }
  function forceLangLock(L){
    let n = 0;
    const iv = setInterval(()=>{
      n++;
      dcSend({ type:'session.update', session:{ spoken_language:L, input_audio_transcription:{model:'whisper-1',language:L,temperature:0} }});
      if (n >= 16) clearInterval(iv); // ~8s
    }, 500);
  }
  function sendGreeting(companyName, L, firstQ){
    const intro = (L==='de')
      ? `Willkommen! Dieses Interview wird im Auftrag von ${companyName||'Clarity'} geführt. Bitte antworte ausschließlich auf Deutsch.`
      : `Welcome! This interview is conducted on behalf of ${companyName||'Clarity'}. Please respond strictly in English.`;
    const q = firstQ && String(firstQ).trim()
      ? firstQ
      : (L==='de' ? 'Bist du bereit zu starten?' : 'Are you ready to begin?');

    dcSend({ type:'response.cancel', response:{} });
    dcSend({ type:'response.create', response:{
      conversation:'interview',
      instructions: `${intro} ${q}`,
      modalities:['audio']
    }});
  }

  // -------------------- Media / Recording --------------------
  async function setupLocalMedia(){
    // Hinweis: wenn in Wix in einem iFrame eingebettet, MUSS das iFrame allow="microphone; camera; autoplay" haben.
    try {
      localStream = await navigator.mediaDevices.getUserMedia({
        audio:{ echoCancellation:true, noiseSuppression:true, autoGainControl:true },
        video:true
      });
    } catch (e){
      log('getUserMedia failed:', e);
      setStatus('err', 'Mic/Kamera blockiert (iFrame „allow“ oder Browser-Permission prüfen).');
      throw e;
    }
    $localV.srcObject = localStream;

    try{
      const ctx = new (window.AudioContext || window.webkitAudioContext)();
      const src = ctx.createMediaStreamSource(localStream);
      const analyser = ctx.createAnalyser();
      analyser.fftSize = 512;
      const buf = new Uint8Array(analyser.frequencyBinCount);
      src.connect(analyser);
      (function tick(){
        analyser.getByteTimeDomainData(buf);
        let dev=0; for(let i=0;i<buf.length;i++) dev=Math.max(dev, Math.abs(buf[i]-128));
        $mic.style.width = Math.min(100, dev*2) + '%';
        requestAnimationFrame(tick);
      })();
    }catch(_){}
  }

  function ensureAudioPlayback(){ return $remoteA.play().then(()=>true).catch(()=>false); }
  function showAudioGate(){ setStatus('warn','Audio-Autoplay blockiert – bitte Player anklicken.'); }

  // -------------------- Upload: direkt in WIX MEDIA --------------------
  async function blobToBase64(blob){
    const buf = await blob.arrayBuffer();
    let binary = '';
    const bytes = new Uint8Array(buf);
    const CH = 0x8000;
    for (let i=0;i<bytes.length;i+=CH){
      binary += String.fromCharCode.apply(null, bytes.subarray(i, i+CH));
    }
    return btoa(binary);
  }

  async function uploadToWixMedia(blob){
    try{
      $upState.textContent = 'uploading';
      $recProg.style.width = '15%';
      const b64 = await blobToBase64(blob);
      $recProg.style.width = '35%';

      const r = await fetch(WIX_UPLOAD_URL, {
        method:'POST',
        headers:{ 'Content-Type':'application/json' },
        body: JSON.stringify({
          base64: `data:video/webm;base64,${b64}`,
          fileName: `${UID||'IV'}-${Date.now()}.webm`,
          uid: UID,
          companyId: COMPANY_ID,
        })
      });
      $recProg.style.width = '65%';

      if (!r.ok){
        const t = await r.text().catch(()=>String(r.status));
        throw new Error('wix_upload_http_'+t);
      }
      const j = await r.json().catch(()=> ({}));
      if (!j?.ok) throw new Error(j?.error || 'wix_upload_failed');

      $recProg.style.width = '100%';
      $upState.textContent = 'uploaded';
      parent?.postMessage?.({ type:'media.upload.done', data:{ url:j.fileUrl, mediaId:j.mediaId } }, '*');
      log('[REC] upload ok -> Wix Media', j.fileUrl||'');
    }catch(e){
      $upState.textContent = 'upload failed';
      parent?.postMessage?.({ type:'media.upload.error', data:{ message:String(e?.message||e) } }, '*');
      log('[REC] upload failed', e);
    }
  }

  // -------------------- Recording --------------------
  function startRecording(){
    if (!localStream){ log('[REC] cannot start – no localStream'); return; }

    const ctx = new (window.AudioContext || window.webkitAudioContext)();
    const dest = ctx.createMediaStreamDestination();

    const micSrc = ctx.createMediaStreamSource(localStream);
    micSrc.connect(dest);

    if (remoteStream){
      try{ ctx.createMediaStreamSource(remoteStream).connect(dest); }catch(e){ log('[REC] remote mix fail', e); }
    }

    mixedStream = new MediaStream();
    dest.stream.getAudioTracks().forEach(t => mixedStream.addTrack(t));
    const cam = localStream.getVideoTracks()[0];
    if (cam) mixedStream.addTrack(cam);

    mediaRecorder = new MediaRecorder(mixedStream, {
      mimeType:'video/webm;codecs=vp8,opus',
      videoBitsPerSecond: 1_200_000,
      audioBitsPerSecond: 128_000
    });

    const chunks = [];
    mediaRecorder.onstart = ()=>{ $recState.textContent='recording'; log('[REC] started'); };
    mediaRecorder.ondataavailable = (e)=>{ if (e.data && e.data.size>0) chunks.push(e.data); };
    mediaRecorder.onstop = async ()=>{
      $recState.textContent='stopped';
      const blob = new Blob(chunks, { type:'video/webm' });
      log('[REC] stop, size=', blob.size);
      await uploadToWixMedia(blob);
    };

    mediaRecorder.start();
  }

  function stopRecording(){
    try{ if (mediaRecorder && mediaRecorder.state!=='inactive') mediaRecorder.stop(); }catch(_){}
    try{ mixedStream?.getTracks()?.forEach(t => t.stop()); }catch(_){}
  }

  // -------------------- Start / Stop Flow --------------------
  async function startInterview(){
    setStatus('info','Initialisiere…');

    await setupLocalMedia();

    const { secret, meta } = await getRealtimeToken({
      uid:UID, companyId:COMPANY_ID, lang:LANG, voice:VOICE, debug:true, allowNoInvite:true
    });
    if (!secret) throw new Error('token_missing');

    const EFFECTIVE_LANG  = normLang(meta?.reportLang || meta?.lang || LANG);
    const EFFECTIVE_VOICE = (meta?.voice || VOICE);
    const MODEL           = (meta?.model || 'gpt-4o-realtime-preview');
    const COMPANY_NAME    = (meta?.companyName || 'Clarity');
    const FIRST_Q         = (meta?.firstQuestion || '');

    log('[Live] effective', { lang: EFFECTIVE_LANG, voice: EFFECTIVE_VOICE, model: MODEL });

    await connectRealtime(secret, MODEL);

    const unlocked = await ensureAudioPlayback();
    if (!unlocked) showAudioGate();

    startRecording();

    await waitDCOpen();
    dcSend({ type:'response.cancel', response:{} });

    primeSession(EFFECTIVE_LANG, EFFECTIVE_VOICE);
    forceLangLock(EFFECTIVE_LANG);
    setTimeout(()=> sendGreeting(COMPANY_NAME, EFFECTIVE_LANG, FIRST_Q), 120);

    setStatus('ok','Verbunden • Interview läuft');
  }

  function hangup(){
    // Kostenbremse: alle laufenden Responses & VAD aus
    try { dcSend({ type:'response.cancel', response:{} }); } catch(_){}
    try { dcSend({ type:'session.update', session:{ turn_detection:{ type:'none' } } }); } catch(_){}
    stopRecording();
    try{ pc?.close(); }catch(_){}
    try{ localStream?.getTracks()?.forEach(t => t.stop()); }catch(_){}
    try{ remoteStream?.getTracks()?.forEach(t => t.stop()); }catch(_){}
    setStatus('warn','Beendet');
    log('[Live] hangup done');
  }

  // -------------------- Parent-Messaging --------------------
  window.addEventListener('message', (ev)=>{
    const msg = ev.data || {};
    if (msg.type === 'clarity.live.start') {
      startInterview().catch(e => { setStatus('err', 'Startfehler: ' + (e?.message||e)); log(e); });
    } else if (msg.type === 'clarity.live.hangup') {
      hangup();
    }
  });

  document.getElementById('btnStop').addEventListener('click', hangup);

  // Optional Autostart (auskommentieren, wenn Parent startet)
  // startInterview().catch(e => { setStatus('err', 'Startfehler: ' + (e?.message||e)); log(e); });
  </script>
</body>
</html>
