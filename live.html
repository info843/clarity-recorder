// backend/http-functions.js
import { response } from 'wix-http-functions';
import { getSecret } from 'wix-secrets-backend';

/** CORS */
function corsHeaders(request) {
  const reqOrigin =
    request?.headers?.origin ||
    request?.headers?.get?.('origin') ||
    '';

  const ALLOW = [
    'https://interview.clarity-nvl.com',
    'https://www.clarity-nvl.com'
  ];
  const allowOrigin = ALLOW.includes(reqOrigin) ? reqOrigin : ALLOW[0];

  return {
    'Access-Control-Allow-Origin': allowOrigin,
    'Access-Control-Allow-Methods': 'OPTIONS, POST',
    'Access-Control-Allow-Headers': 'Authorization, Content-Type',
    'Vary': 'Origin',
    'Content-Type': 'application/json'
  };
}

/** Preflight */
export function options_realtimeToken(request) {
  return response({ status: 204, headers: corsHeaders(request) });
}

/**
 * POST /_functions/realtimeToken
 * Body: { uid, companyId, lang, voice, model }
 * Returns: { ok:true, token, model }
 */
export async function post_realtimeToken(request) {
  const headers = corsHeaders(request);

  try {
    const raw = await request.body.text();
    const body = raw ? JSON.parse(raw) : {};

    const voice = body.voice || 'verse';
    const lang  = (body.lang || 'de').toLowerCase();
    const model = body.model || 'gpt-4o-realtime-preview-2025-09-12';

    const apiKey =
      (await getSecret('openai_api_key').catch(() => null)) ||
      (await getSecret('OPENAI_API_KEY').catch(() => null));

    if (!apiKey) {
      return response({
        status: 500,
        headers,
        body: { ok: false, error: 'OPENAI_API_KEY missing in Wix Secrets' }
      });
    }

    // Create short-lived realtime session (ðŸ”Š audio enabled via Beta header)
    const upstream = await fetch('https://api.openai.com/v1/realtime/sessions', {
      method: 'POST',
      headers: {
        Authorization: `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
        'OpenAI-Beta': 'realtime=v1' // <<< wichtig fÃ¼r Audio
      },
      body: JSON.stringify({
        model,
        modalities: ['audio', 'text'],
        voice,
        instructions: lang.startsWith('de')
          ? 'Du fÃ¼hrst ein professionelles deutschsprachiges Interview. Sprich klar, in kurzen SÃ¤tzen.'
          : 'You conduct a professional interview. Speak clearly in short sentences.'
      })
    });

    if (!upstream.ok) {
      const errText = await upstream.text().catch(() => '');
      return response({
        status: upstream.status,
        headers,
        body: { ok: false, error: 'OPENAI_SESS_CREATE_FAILED', detail: errText }
      });
    }

    const data = await upstream.json();
    const token = data?.client_secret?.value;

    if (!token) {
      return response({
        status: 502,
        headers,
        body: { ok: false, error: 'NO_TOKEN_FROM_OPENAI' }
      });
    }

    return response({
      status: 200,
      headers,
      body: { ok: true, token, model: data?.model || model }
    });
  } catch (e) {
    return response({
      status: 500,
      headers,
      body: { ok: false, error: e?.message || 'UNKNOWN' }
    });
  }
}
html
Copy code
<!-- live.html -->
<!doctype html>
<html lang="de">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>CLARITY Interview Live</title>
  <style>
    :root { --bg:#0b1020; --panel:#131a2e; --muted:#6b7280; }
    *{box-sizing:border-box}
    body{margin:0;background:var(--bg);color:#e5e7eb;font-family:ui-sans-serif,system-ui,Segoe UI,Roboto,Arial}
    .wrap{max-width:1100px;margin:0 auto;padding:20px;display:grid;grid-template-columns:1fr 360px;gap:20px}
    .card{background:var(--panel);border-radius:14px;padding:16px;box-shadow:0 10px 30px rgba(0,0,0,.35)}
    .row{display:grid;grid-template-columns:1fr 1fr;gap:10px}
    label{display:block;font-size:12px;color:#9ca3af;margin-bottom:6px}
    input,select,button,textarea{width:100%;padding:10px 12px;border-radius:10px;border:1px solid #334155;background:#0f172a;color:#e5e7eb}
    button{cursor:pointer}
    button.primary{background:#2563eb;border-color:#1e40af}
    button.ghost{background:transparent;border-color:#475569}
    textarea{min-height:110px;resize:vertical}
    .pill{display:inline-flex;align-items:center;gap:8px;background:#0f172a;border:1px solid #334155;padding:6px 10px;border-radius:999px;font-size:12px;color:#cbd5e1}
    #status{height:280px;overflow:auto;font-family:ui-monospace,Consolas,monospace;background:#0b1222;border:1px solid #1f2937;border-radius:10px;padding:10px}
    #video{width:100%;aspect-ratio:16/9;background:#000;border-radius:12px}
    audio{width:100%}
  </style>
</head>
<body>
<div class="wrap">
  <div class="card">
    <div style="display:flex;justify-content:space-between;align-items:center;margin-bottom:12px">
      <div class="pill">state: <b id="stateTxt">idle</b></div>
      <div class="pill">model: <b id="modelTxt">â€”</b></div>
    </div>

    <div class="row">
      <div>
        <label>UID</label>
        <input id="uid" placeholder="IV-XXXX" />
      </div>
      <div>
        <label>Company ID</label>
        <input id="company" placeholder="NVL-02" />
      </div>
    </div>

    <div class="row" style="margin-top:10px">
      <div>
        <label>Language</label>
        <select id="lang">
          <option value="de">de</option>
          <option value="en">en</option>
        </select>
      </div>
      <div>
        <label>Voice</label>
        <select id="voice">
          <option value="verse">verse</option>
          <option value="alloy">alloy</option>
          <option value="aria">aria</option>
        </select>
      </div>
    </div>

    <div class="row" style="margin-top:10px">
      <div>
        <label>Token Endpoint</label>
        <!-- <<< Default auf Wix-HTTP-Function -->
        <input id="tokenUrl" value="/_functions/realtimeToken" />
      </div>
      <div>
        <label>Mux Upload API (optional)</label>
        <input id="muxUrl" value="/api/mux-upload" />
      </div>
    </div>

    <div class="row" style="margin-top:14px">
      <button id="btnStart" class="primary">Start Live</button>
      <button id="btnStop" class="ghost">Stop</button>
    </div>

    <h4 style="margin:16px 0 6px">Status</h4>
    <div id="status"></div>
  </div>

  <div class="card">
    <h3 style="margin-top:0">Agent Audio</h3>
    <audio id="agentAudio" controls></audio>
    <button id="btnUnlock" style="margin-top:8px" class="ghost">Audio entsperren</button>

    <h3 style="margin-top:16px">Preview (Your Camera)</h3>
    <video id="video" autoplay playsinline muted></video>

    <h3 style="margin-top:16px">Agent Text</h3>
    <textarea id="agentText" placeholder="Agent messagesâ€¦" readonly></textarea>
  </div>
</div>

<script>
const els = {
  uid:        document.getElementById('uid'),
  company:    document.getElementById('company'),
  lang:       document.getElementById('lang'),
  voice:      document.getElementById('voice'),
  tokenUrl:   document.getElementById('tokenUrl'),
  muxUrl:     document.getElementById('muxUrl'),
  btnStart:   document.getElementById('btnStart'),
  btnStop:    document.getElementById('btnStop'),
  btnUnlock:  document.getElementById('btnUnlock'),
  status:     document.getElementById('status'),
  modelTxt:   document.getElementById('modelTxt'),
  stateTxt:   document.getElementById('stateTxt'),
  audio:      document.getElementById('agentAudio'),
  video:      document.getElementById('video'),
  agentText:  document.getElementById('agentText')
};

const log = (...a) => {
  const t = new Date().toLocaleTimeString();
  els.status.textContent += `[${t}] ${a.join(' ')}\n`;
  els.status.scrollTop = els.status.scrollHeight;
  console.log(...a);
};

// URL-Params Ã¼bernehmen
(() => {
  const p = new URLSearchParams(location.search);
  if (p.get('uid')) els.uid.value = p.get('uid');
  if (p.get('companyId')) els.company.value = p.get('companyId');
  if (p.get('lang')) els.lang.value = p.get('lang');
  if (p.get('voice')) els.voice.value = p.get('voice');
  log('Token endpoint:', els.tokenUrl.value);
})();

let pc = null;
let dc = null;
let mediaStream = null;
let audioUnlocked = false;
let stopRecording = null;

els.btnUnlock.addEventListener('click', async () => {
  try { await els.audio.play(); audioUnlocked = true; log('Audio entsperrt'); }
  catch (e) { log('Audio entsperren fehlgeschlagen:', e?.message || e); }
});

els.btnStart.addEventListener('click', async () => {
  els.stateTxt.textContent = 'starting';
  try {
    // 1) Mic + Cam
    mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true, video: true });
    els.video.srcObject = mediaStream;

    // 2) Token holen
    log('Token endpoint:', els.tokenUrl.value);
    log('Fetching tokenâ€¦', JSON.stringify({
      uid: els.uid.value, companyId: els.company.value, lang: els.lang.value, voice: els.voice.value
    }));

    const tokenRes = await fetch(els.tokenUrl.value, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        uid: els.uid.value,
        companyId: els.company.value,
        lang: els.lang.value,
        voice: els.voice.value
      })
    }).catch(err => { throw new Error('TOKEN_FETCH_FAILED ' + err?.message); });

    const tokenJson = await tokenRes.json().catch(() => ({}));
    if (!tokenRes.ok || !tokenJson?.ok || !tokenJson?.token) {
      throw new Error(`TOKEN_BAD_RESPONSE status=${tokenRes.status} body=${JSON.stringify(tokenJson)}`);
    }
    const { token, model } = tokenJson;
    els.modelTxt.textContent = model || 'â€”';
    log('Token OK');

    // 3) PeerConnection
    pc = new RTCPeerConnection();
    pc.onconnectionstatechange = () => log('pc:', pc.connectionState);
    pc.oniceconnectionstatechange = () => log('ice:', pc.iceConnectionState);

    // Mic senden + Agent-Audio explizit empfangen
    const micTrack = mediaStream.getAudioTracks()[0];
    if (micTrack) pc.addTrack(micTrack, mediaStream);
    pc.addTransceiver('audio', { direction: 'recvonly' });

    // Cam nur lokal (wenn du Remote-Video willst: zusÃ¤tzlich recvonly video)
    const camTrack = mediaStream.getVideoTracks()[0];
    if (camTrack) pc.addTrack(camTrack, mediaStream);

    pc.ontrack = (ev) => {
      log('ontrack kind=', ev.track?.kind, 'streams=', ev.streams?.length);
      if (ev.track.kind === 'audio' && ev.streams?.[0]) {
        els.audio.srcObject = ev.streams[0];
        if (audioUnlocked) els.audio.play().catch(()=>{});
      }
    };

    // 4) DataChannel
    dc = pc.createDataChannel('oai-events');
    dc.onopen = () => {
      log('DataChannel open');
      dc.send(JSON.stringify({
        type: 'response.create',
        response: {
          instructions: els.lang.value === 'de'
            ? 'Bitte begrÃ¼ÃŸe die Kandidatin/den Kandidaten freundlich und stelle eine erste kurze Warm-up-Frage.'
            : 'Please greet the candidate and ask a short warm-up question.',
          modalities: ['audio', 'text'],
          voice: els.voice.value
        }
      }));
    };
    dc.onmessage = (e) => {
      try {
        const msg = JSON.parse(e.data);
        if (msg?.type === 'response.output_text.delta' && msg?.delta) {
          els.agentText.value += msg.delta;
          els.agentText.scrollTop = els.agentText.scrollHeight;
        }
      } catch {/* ignore */}
    };

    // 5) SDP
    const offer = await pc.createOffer();
    await pc.setLocalDescription(offer);

    const rt = await fetch(`https://api.openai.com/v1/realtime?model=${encodeURIComponent(model)}`, {
      method: 'POST',
      headers: {
        Authorization: `Bearer ${token}`,
        'Content-Type': 'application/sdp',
        'OpenAI-Beta': 'realtime=v1' // <<< wichtig fÃ¼r Audio
      },
      body: offer.sdp
    }).catch(err => { throw new Error('SDP_POST_FAILED ' + err?.message); });

    if (!rt.ok) throw new Error(`SDP_EXCHANGE_FAILED ${rt.status} ${await rt.text()}`);
    const answer = { type: 'answer', sdp: await rt.text() };
    await pc.setRemoteDescription(answer);

    els.stateTxt.textContent = 'connected';
    log('Realtime connected');

    // 6) Optional: Mux Upload
    try {
      const mr = new MediaRecorder(mediaStream, { mimeType: 'video/webm;codecs=vp9,opus' });
      const chunks = [];
      mr.ondataavailable = e => e.data && chunks.push(e.data);
      mr.onstop = async () => {
        try {
          const blob = new Blob(chunks, { type: 'video/webm' });
          const fd = new FormData();
          fd.append('file', blob, `clarity-interview-${Date.now()}.webm`);
          const up = await fetch(els.muxUrl.value, { method: 'POST', body: fd });
          const j = await up.json().catch(()=> ({}));
          if (up.ok) log('Mux upload OK, uploadId:', j?.id || j?.uploadId || 'n/a');
          else log('Mux upload failed', up.status, JSON.stringify(j));
        } catch (e) { log('Mux upload error', e?.message || e); }
      };
      mr.start(1000);
      stopRecording = () => { try { mr.stop(); } catch {} };
      log('MediaRecorder started (video+audio)');
    } catch (e) {
      log('MediaRecorder not supported or init failed:', e?.message || e);
    }
  } catch (e) {
    els.stateTxt.textContent = 'error';
    log('ERROR:', e?.message || e);
  }
});

els.btnStop.addEventListener('click', () => {
  try { if (dc) dc.close(); } catch {}
  try { if (pc) pc.close(); } catch {}
  pc = null; dc = null;

  if (mediaStream) {
    mediaStream.getTracks().forEach(t => t.stop());
    mediaStream = null;
  }
  if (typeof stopRecording === 'function') {
    try { stopRecording(); } catch {}
    stopRecording = null;
  }

  els.stateTxt.textContent = 'stopped';
  log('Stopped');
});
</script>
</body>
</html>
